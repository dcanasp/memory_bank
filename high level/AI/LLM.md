The core of the LLM is trying to create a model that can solve multiple similar problems. And the solution was with [[Transformers]] 


GPT (generalized pretrained transformers) are a bunch of transformers trained with a lot of data about mostly every subject 

After this, you can do a [[fine tunning]] so it shapes the answers (but this is harder to get preciselly)

