Multiple words enter, you have a [[neural network]] and multiple times enters to that network each word. These networks always have the same weights and biases

RNN are always sequential and always the output of the last iteration is taking into account in the input.

These RNN have a big problem, gradient vanishing. So the context is being forgotten


